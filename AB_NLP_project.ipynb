{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "NOUN-VERB pairs"
      ],
      "metadata": {
        "id": "rDsOvVQTku-2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSh42bnEkUXV",
        "outputId": "c13246e4-0e2a-4d78-d080-1acc1ac113d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "sentences = ['The company made a bad decision',\n",
        "             'The team performed well in the game',\n",
        "             'The restaurant served delicious food',\n",
        "             'The movie was poorly directed']\n",
        "\n",
        "extracted_aspects = []"
      ],
      "metadata": {
        "id": "qfWACgP4kccc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "    doc = nlp(sentence)\n",
        "    aspect_pairs = {}\n",
        "    for token in doc:\n",
        "        if token.pos_ in ('NOUN', 'VERB'):\n",
        "            children = [child for child in token.children if child.pos_ in ('ADJ', 'ADV', 'NOUN')]\n",
        "            if children:\n",
        "                aspect_pairs[token.text] = children\n",
        "    if aspect_pairs:\n",
        "        extracted_aspects.append(aspect_pairs)"
      ],
      "metadata": {
        "id": "GXW7CitYklKc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extracted_aspects)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cUHFh33knU7",
        "outputId": "c35fabb9-462f-4f3a-ddbd-bdd561c1e2e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'made': [company, decision], 'decision': [bad]}, {'performed': [team, well]}, {'served': [restaurant, food], 'food': [delicious]}, {'directed': [movie, poorly]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Negatition and Compound words"
      ],
      "metadata": {
        "id": "peJNVSdApP--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "    doc = nlp(sentence)\n",
        "    aspect_pairs = {}\n",
        "    for token in doc:\n",
        "        if token.pos_ == 'NOUN':\n",
        "            modifiers = []\n",
        "            for child in token.children:\n",
        "                if child.pos_ in ('ADJ', 'ADV', 'VERB'):\n",
        "                    modifiers.append(child)\n",
        "                elif child.dep_ == 'neg':\n",
        "                    for grandchild in child.children:\n",
        "                        if grandchild.pos_ in ('ADJ', 'ADV', 'VERB'):\n",
        "                            modifiers.append(grandchild)\n",
        "            if modifiers:\n",
        "                # Check for compound nouns\n",
        "                compound_nouns = []\n",
        "                for possible_compound in doc[token.i:]:\n",
        "                    if possible_compound.pos_ == 'NOUN':\n",
        "                        if possible_compound.dep_ == 'compound' or possible_compound.n_lefts > 0:\n",
        "                            compound_nouns.append(possible_compound)\n",
        "                        else:\n",
        "                            break\n",
        "                    else:\n",
        "                        break\n",
        "                if compound_nouns:\n",
        "                    compound_noun_text = ' '.join([cn.text for cn in compound_nouns] + [token.text])\n",
        "                    aspect_pairs[compound_noun_text] = modifiers\n",
        "                else:\n",
        "                    aspect_pairs[token.text] = modifiers\n",
        "        elif token.pos_ == 'VERB':\n",
        "            noun_objects = []\n",
        "            for child in token.children:\n",
        "                if child.pos_ == 'NOUN':\n",
        "                    noun_objects.append(child)\n",
        "            if noun_objects:\n",
        "                named_entities = []\n",
        "                for no in noun_objects:\n",
        "                    if no.ent_type_ != 0:\n",
        "                        named_entities.append(no)\n",
        "                if named_entities:\n",
        "                    named_entity_text = ' '.join([ne.text for ne in named_entities])\n",
        "                    aspect_pairs[named_entity_text] = [token]\n",
        "                else:\n",
        "                    aspect_pairs[token.text] = noun_objects\n",
        "    if aspect_pairs:\n",
        "        extracted_aspects.append(aspect_pairs)"
      ],
      "metadata": {
        "id": "dUOpg9jxo6yY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extracted_aspects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V730fFKfo--v",
        "outputId": "e66e9b33-b67c-4ca3-f26f-8a27a392bae4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'made': [company, decision], 'decision': [bad]}, {'performed': [team, well]}, {'served': [restaurant, food], 'food': [delicious]}, {'directed': [movie, poorly]}, {'company decision': [made], 'decision decision': [bad]}, {'team': [performed]}, {'restaurant food': [served], 'food food': [delicious]}, {'movie': [directed]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['The company made a bad decision',\n",
        "             'The team performed well in the game',\n",
        "             'The restaurant served delicious food',\n",
        "             'The food was not delicious',\n",
        "             'The car engine is broken',\n",
        "             'John is a good employee']\n",
        "\n",
        "extracted_aspects = []"
      ],
      "metadata": {
        "id": "OiYgkKet0FLQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "    doc = nlp(sentence)\n",
        "    aspect_pairs = {}\n",
        "    for token in doc:\n",
        "        if token.pos_ == 'NOUN':\n",
        "            # Check for adjective, adverb, and verb modifiers of the noun\n",
        "            modifiers = []\n",
        "            for child in token.children:\n",
        "                if child.pos_ in ('ADJ', 'ADV', 'VERB'):\n",
        "                    modifiers.append(child)\n",
        "                elif child.dep_ == 'neg':\n",
        "                    # Check for negation of modifiers\n",
        "                    for grandchild in child.children:\n",
        "                        if grandchild.pos_ in ('ADJ', 'ADV', 'VERB'):\n",
        "                            modifiers.append(grandchild)\n",
        "            if modifiers:\n",
        "                # Check for compound nouns\n",
        "                compound_nouns = []\n",
        "                for possible_compound in doc[token.i:]:\n",
        "                    if possible_compound.pos_ == 'NOUN':\n",
        "                        if possible_compound.dep_ == 'compound' or possible_compound.n_lefts > 0:\n",
        "                            compound_nouns.append(possible_compound)\n",
        "                        else:\n",
        "                            break\n",
        "                    else:\n",
        "                        break\n",
        "                if compound_nouns:\n",
        "                    compound_noun_text = ' '.join([cn.text for cn in compound_nouns] + [token.text])\n",
        "                    aspect_pairs[compound_noun_text] = modifiers\n",
        "                else:\n",
        "                    aspect_pairs[token.text] = modifiers\n",
        "        elif token.pos_ == 'VERB':\n",
        "            # Check for noun objects of the verb\n",
        "            noun_objects = []\n",
        "            for child in token.children:\n",
        "                if child.pos_ == 'NOUN':\n",
        "                    noun_objects.append(child)\n",
        "            if noun_objects:\n",
        "                # Check for named entities\n",
        "                named_entities = []\n",
        "                for no in noun_objects:\n",
        "                    if no.ent_type_ != 0:\n",
        "                        named_entities.append(no)\n",
        "                if named_entities:\n",
        "                    named_entity_text = ' '.join([ne.text for ne in named_entities])\n",
        "                    aspect_pairs[named_entity_text] = [token]\n",
        "                else:\n",
        "                    aspect_pairs[token.text] = noun_objects\n",
        "    if aspect_pairs:\n",
        "        extracted_aspects.append(aspect_pairs)"
      ],
      "metadata": {
        "id": "F3hvXL6g0K2K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extracted_aspects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr2g2D7z0MmW",
        "outputId": "51ce8b32-1485-4223-8679-0a9a42c15ee4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'company decision': [made], 'decision decision': [bad]}, {'team': [performed]}, {'restaurant food': [served], 'food food': [delicious]}, {'engine': [broken]}, {'employee employee': [good]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Failed trial 1"
      ],
      "metadata": {
        "id": "AMGdzuuWqVJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['The root causes were identified as follows: Root Cause for Sub-Problem 1: Inadequate procedural guidance and unclear coordination between applicable proceduers',\n",
        "            'This ultimately created an environment that promulgated a human error-likely environment.” More specifically, the RCE team determined that the environment consisted of poor communication, lack of engineering leadership, too much reliance on vendor designs, time pressure, and distractions. ',\n",
        "            'Also, equipment problems due to aging have led to an increasingly negative trend in the station’s Deficient Critical Component Backlog Orders. ',\n",
        "             'The movie was not good.',\n",
        "             'Mr. Baldwin stated the deficient performance was caused by maintenance procedural inadequacy which allowed work to proceed with the relay energized.'\n",
        "            ]\n",
        "\n",
        "extracted_aspects = []\n",
        "\n",
        "for sentence in sentences:\n",
        "    doc = nlp(sentence)\n",
        "    noun_adj_pairs = {}\n",
        "    for token in doc:\n",
        "        adj = []\n",
        "        noun = \"\"\n",
        "        if token.pos_ == 'NOUN':\n",
        "            if token.dep_ == 'compound':\n",
        "                compound_noun = [t.text for t in token.subtree]\n",
        "                noun = \" \".join(compound_noun)\n",
        "            else:\n",
        "                noun = token.text\n",
        "            for child in token.children:\n",
        "                if child.pos_ == 'ADJ':\n",
        "                    if 'neg' in [t.dep_ for t in child.head.children]:\n",
        "                        adj.append('not ' + child.text)\n",
        "                    else:\n",
        "                        adj.append(child.text)\n",
        "        if noun and adj:\n",
        "            if 'neg' in [t.dep_ for t in token.head.children]:\n",
        "                noun_adj_pairs.update({noun:['not ' + a for a in adj]})\n",
        "            else:\n",
        "                noun_adj_pairs.update({noun:adj})\n",
        "    named_entities = [ent.text for ent in doc.ents if ent.label_ in ['PERSON', 'ORG', 'GPE']]\n",
        "    if len(noun_adj_pairs) != 0:\n",
        "        extracted_aspects.append({'aspects': noun_adj_pairs, 'entities': named_entities})\n",
        "\n",
        "print(extracted_aspects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZzRNa_S0Naw",
        "outputId": "d42c7037-4bef-473a-b5fb-f7f01ab66905"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'aspects': {'guidance': ['Inadequate', 'procedural'], 'coordination': ['unclear'], 'proceduers': ['applicable']}, 'entities': ['Root Cause']}, {'aspects': {'environment': ['human', 'likely'], 'communication': ['poor'], 'reliance': ['much']}, 'entities': []}, {'aspects': {'problems': ['due'], 'trend': ['negative']}, 'entities': ['Deficient Critical Component Backlog Orders']}, {'aspects': {'performance': ['deficient'], 'inadequacy': ['procedural']}, 'entities': ['Baldwin']}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Failed trial 2"
      ],
      "metadata": {
        "id": "HLYuRqQrqMPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_n = \"The movie was not good.\"\n",
        "\n",
        "doc = nlp(sentence_n)\n",
        "noun_adj_pairs = {}\n",
        "for token in doc:\n",
        "    adj = []\n",
        "    noun = \"\"\n",
        "    if token.pos_ == 'NOUN':\n",
        "        for child in token.children:\n",
        "            if child.pos_ == 'ADJ':\n",
        "                noun = token.text\n",
        "                adj.append(child)\n",
        "            elif child.dep_ == 'neg':\n",
        "                adj.append(token)\n",
        "    if noun and adj != []:\n",
        "        noun_adj_pairs.update({noun:adj})\n",
        "\n",
        "print(noun_adj_pairs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc8U254-TXyB",
        "outputId": "817f632d-7fa3-4f10-cdb1-26d708606468"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Failed trial 3\n"
      ],
      "metadata": {
        "id": "Afhb86QLqHXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The movie was not good.\"\n",
        "\n",
        "doc = nlp(sentence)\n",
        "noun_adj_pairs = {}\n",
        "for token in doc:\n",
        "    adj = []\n",
        "    noun = \"\"\n",
        "    if token.pos_ == 'NOUN':\n",
        "        for child in token.children:\n",
        "            if child.pos_ == 'ADJ':\n",
        "                noun = token.text\n",
        "                adj.append(child)\n",
        "            elif child.dep_ == 'neg':\n",
        "                adj.append(token)\n",
        "        if noun or adj:\n",
        "            noun_adj_pairs.update({noun: adj})\n",
        "\n",
        "print(noun_adj_pairs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_00VA5MWjsv",
        "outputId": "fa7442bc-b0d3-4be4-ba1d-53ff2c8725c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n"
          ]
        }
      ]
    }
  ]
}